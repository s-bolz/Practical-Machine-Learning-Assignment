# Human Activity Recognition Analysis

This analysis is part of the programming assignment for the MOOC
[Practical Machine Learning](https://www.coursera.org/course/predmachlearn). It
uses the
[Weight Lifting Dataset](http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201)
by E. Velloso, A. Bulling, H. Gellersen, W. Ugulino, and H. Fuks to predict the
quality of barbell lifts.

## Loading, Subsetting and Splitting the Data

We start with downloading the training and testing data sets and loading both sets into R. We rename the testing data set into submission data set as we will later split off a testing data set from our training data set with which we estimate the out of sample error rate.

```{r, cache = TRUE}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv", "curl")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-submission.csv", "pml-submission.csv", "curl")
training <- read.csv("pml-training.csv")
submission <- read.csv("pml-testing.csv")
```

What are the dimensions of both data sets?

```{r}
data.frame (
    trainingDimensions = dim(training),
    submissionDimensions  = dim(submission)
)
```

Both data sets have the same number of columns. Let's have a look if some of them are different.

```{r}
data.frame (
    notInsubmission  = setdiff(names(training), names(submission)),
    notInTraining = setdiff(names(submission), names(training))
)
```

The submission data set has no outcome variable but has an identifier column instead. This was expected and does not offer us any possibility to reduce the predictors from the training set. Now let's have a look at NA's. If we find fields that have lots of NA's in the submission data set it would be sensible to exclude these variables from our model.

```{r}
library(plyr)
naPropSubmission <- sapply(1:dim(submission)[2], function(x){mean(is.na(submission[, x]))})
count(data.frame(naPropSubmission), "naPropSubmission")
```

100 variables in the submission data set have no value at all. We don't want them in our model so we remove them from our training data set.

```{r}
trainingSubset <- training[, naPropSubmission < 1]
naPropTraining <- sapply(1:dim(trainingSubset)[2], function(x){mean(is.na(trainingSubset[, x]))})
count(data.frame(naPropTraining), "naPropTraining")
```

Now all our training and submission variables have no NA's left at all. Let's look at the first columns of the submission data set.

```{r}
submission[1:6]
```

The goal of the assignment is to predict the outcome with data from the accelerometers which is why we will exclude the timestamp and time window information from our model. The X column looks to be some kind of identifier or row number. Let's verify this by testing it for uniqueness and its range in both data sets.

```{r}
data.frame (
    data_set = c("training", "submission"),
    unique_x = c(length(unique(training$X)), length(unique(submission$X))),
    min_x    = c(min(unique(training$X)), min(unique(submission$X))),
    max_x    = c(max(unique(training$X)), max(unique(submission$X))),
    rows     = c(dim(training)[1], dim(submission)[1])
)
```

This proves it and makes us exclude the variable from our model as well. Now let's have a look at the user column. We want to if both data sets cover the same users and how many training data we have per user.

```{r}
trainingUsers <- count(training, "user_name")
names(trainingUsers)[2] <- "training_records"
submissionUsers <- count(submission, "user_name")
names(submissionUsers)[2] <- "submission_records"
merge(trainingUsers, submissionUsers)
```

We have several thousand training observations per user in the submission data set. This enables us to build a separate model per user.

```{r}
library(caret)
```
